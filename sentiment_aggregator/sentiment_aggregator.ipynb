{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy \n",
    "nlp = spacy.load('en')\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from collections import Counter \n",
    "from bs4 import BeautifulSoup \n",
    "import nltk\n",
    "from nltk.corpus import sentiwordnet as swn\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.util import ngrams\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.stem import WordNetLemmatizer\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "from nltk.stem import SnowballStemmer\n",
    "snowball_stemmer = SnowballStemmer(\"english\")\n",
    "stop = set(stopwords.words('english'))\n",
    "\n",
    "import pickle\n",
    "\n",
    "def dump(obj,filename):\n",
    "    filehandler = open(filename,\"wb\")\n",
    "    pickle.dump(obj,filehandler)\n",
    "    filehandler.close()\n",
    "\n",
    "def load(filename):\n",
    "    file = open(filename,'rb')\n",
    "    obj = pickle.load(file)\n",
    "    file.close()\n",
    "    return obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# CLEANS TEXT BY REPLACING CHARACTERS\n",
    "def getCleanText(text, lower = True):\n",
    "    text = str(text)\n",
    "    parse_text = BeautifulSoup(text).get_text()\n",
    "    letters_only = re.sub(r'http[s]?:\\/\\/(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', ' url ', \n",
    "                          parse_text, flags=re.MULTILINE)\n",
    "    letters_only = re.sub('^(1?[0-9]|2[0-3]):[0-5][0-9]$','time',letters_only)\n",
    "    letters_only = re.sub('(name|NAME)\\d{1,}','username',letters_only)\n",
    "    letters_only = re.sub(\"[^a-zA-Z0-9\\.:']\",  \n",
    "                      \" \",                   \n",
    "                      letters_only)\n",
    "    letters_only = letters_only.replace('\\n',\" \")\n",
    "    letters_only = letters_only.replace('\\r',\" \")\n",
    "    letters_only = re.sub('[.]{2,}', '. ', letters_only)\n",
    "    if lower:\n",
    "        letters_only = letters_only.lower()\n",
    "    #words = word_tokenize(lower)\n",
    "    words = CountVectorizer(stop_words='english').build_tokenizer()(letters_only)\n",
    "    meaningful_words = [ w for w in words if len(w)> 0 and len(w)<20]\n",
    "    #meaningful_words = [w if (w not in countries) and (w not in cities) else u\"country\" for w in meaningful_words]\n",
    "    #lem_words = [wordnet_lemmatizer.lemmatize(w) for w in  meaningful_words]\n",
    "    #stem_words = [snowball_stemmer.stem(w) for w in lem_words]\n",
    "    clean_text = \" \".join(meaningful_words)\n",
    "    return clean_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def scoring(doc):\n",
    "    stokens = [nltk.word_tokenize(doc)]\n",
    "    taggedlist=[]\n",
    "    for stoken in stokens:        \n",
    "        taggedlist.append(nltk.pos_tag(stoken))\n",
    "    wnl = nltk.WordNetLemmatizer()\n",
    "    score_list=[]\n",
    "    for idx,taggedsent in enumerate(taggedlist):\n",
    "        score_list.append([])\n",
    "        for idx2,t in enumerate(taggedsent):\n",
    "            newtag=''\n",
    "            lemmatized=wnl.lemmatize(t[0])\n",
    "            if t[1].startswith('NN'):\n",
    "                newtag='n'\n",
    "            elif t[1].startswith('JJ'):\n",
    "                newtag='a'\n",
    "            elif t[1].startswith('V'):\n",
    "                newtag='v'\n",
    "            elif t[1].startswith('R'):\n",
    "                newtag='r'\n",
    "            else:\n",
    "                newtag=''       \n",
    "            if(newtag!=''):    \n",
    "                synsets = list(swn.senti_synsets(lemmatized, newtag))\n",
    "                score=0\n",
    "                if(len(synsets)>0):\n",
    "                    for syn in synsets:\n",
    "                        score+=syn.pos_score()-syn.neg_score()\n",
    "                    score_list[idx].append(score/len(synsets))\n",
    "    sentence_sentiment=[]\n",
    "    # get the average score per word\n",
    "    for score_sent in score_list:\n",
    "        if len(score_sent) != 0:\n",
    "            sentence_sentiment.append(sum([word_score for word_score in score_sent])/len(score_sent))\n",
    "        else:\n",
    "            sentence_sentiment.append(0)\n",
    "            continue\n",
    "#    print(\"Sentiment for each sentence for:\"+doc)\n",
    "    return sentence_sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#LOAD LIST FROM DATA\n",
    "# IF WE HAVE TIME ANALYZE DATA USING THE DATAFRAME\n",
    "conversations = load(\"../corpus_doc.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# standarize text for tagging and sentiment scoring\n",
    "clean_conversations = map(getCleanText, conversations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/erikdaily/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 193 of the file /Users/erikdaily/anaconda3/lib/python3.6/runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP})\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP, \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    }
   ],
   "source": [
    "sentiment_scores = map(scoring, clean_conversations)\n",
    "sentence_sentiment = list(sentiment_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = load('../dumps/df_sel_entities.pkl')\n",
    "type(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18340, 17)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>index</th>\n",
       "      <th>Sound Bite Text</th>\n",
       "      <th>Title</th>\n",
       "      <th>Post Type</th>\n",
       "      <th>Media Type</th>\n",
       "      <th>Source Type</th>\n",
       "      <th>Domain</th>\n",
       "      <th>Richness</th>\n",
       "      <th>Interests</th>\n",
       "      <th>Positive Objects</th>\n",
       "      <th>Negative Objects</th>\n",
       "      <th>Topic_top</th>\n",
       "      <th>Topic_id</th>\n",
       "      <th>Topic_raw</th>\n",
       "      <th>Topic_name</th>\n",
       "      <th>entities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Mobile &amp; Apps FILE - In this July 9, 2015, fil...</td>\n",
       "      <td>PepsiCo beats 3Q profit forecasts</td>\n",
       "      <td>Original</td>\n",
       "      <td>No Media</td>\n",
       "      <td>Blogs</td>\n",
       "      <td>mercedsunstar.com</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6:0.987499999969</td>\n",
       "      <td>terms14.png</td>\n",
       "      <td>elise amendola_file ap_the associated press_mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Mobile &amp; Apps FILE - In this July 9, 2015, fil...</td>\n",
       "      <td>PepsiCo beats 3Q profit forecasts</td>\n",
       "      <td>Original</td>\n",
       "      <td>No Media</td>\n",
       "      <td>Blogs</td>\n",
       "      <td>mercedsunstar.com</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6:0.98908045974</td>\n",
       "      <td>terms14.png</td>\n",
       "      <td>elise amendola_file ap_the associated press_mo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  index                                    Sound Bite Text  \\\n",
       "0           0      0  Mobile & Apps FILE - In this July 9, 2015, fil...   \n",
       "1           1      1  Mobile & Apps FILE - In this July 9, 2015, fil...   \n",
       "\n",
       "                               Title Post Type Media Type Source Type  \\\n",
       "0  PepsiCo beats 3Q profit forecasts  Original   No Media       Blogs   \n",
       "1  PepsiCo beats 3Q profit forecasts  Original   No Media       Blogs   \n",
       "\n",
       "              Domain  Richness Interests Positive Objects Negative Objects  \\\n",
       "0  mercedsunstar.com       1.0       NaN              NaN              NaN   \n",
       "1  mercedsunstar.com       1.0       NaN              NaN              NaN   \n",
       "\n",
       "   Topic_top Topic_id         Topic_raw   Topic_name  \\\n",
       "0          6        6  6:0.987499999969  terms14.png   \n",
       "1          6        6   6:0.98908045974  terms14.png   \n",
       "\n",
       "                                            entities  \n",
       "0  elise amendola_file ap_the associated press_mo...  \n",
       "1  elise amendola_file ap_the associated press_mo...  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.shape)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "18340\n"
     ]
    }
   ],
   "source": [
    "sentiment_score=load('./sentiment_per_sentence.pkl')\n",
    "print(type(sentiment_score))\n",
    "print(len(sentiment_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CORRECTION FOR MISTAKE IN ORIGINAL FUNCTION (SHOULD BE SOLVED BY NOW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18340\n"
     ]
    }
   ],
   "source": [
    "z=[]\n",
    "for i in sentiment_score:\n",
    "    if not i:\n",
    "        z.append(0)\n",
    "    for v in i:\n",
    "        if not v:\n",
    "            z.append(0)\n",
    "        else:\n",
    "            z.append(v)\n",
    "print(len(z))\n",
    "sentiment_score = z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### List to column and validation of operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18340, 18)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>index</th>\n",
       "      <th>Sound Bite Text</th>\n",
       "      <th>Title</th>\n",
       "      <th>Post Type</th>\n",
       "      <th>Media Type</th>\n",
       "      <th>Source Type</th>\n",
       "      <th>Domain</th>\n",
       "      <th>Richness</th>\n",
       "      <th>Interests</th>\n",
       "      <th>Positive Objects</th>\n",
       "      <th>Negative Objects</th>\n",
       "      <th>Topic_top</th>\n",
       "      <th>Topic_id</th>\n",
       "      <th>Topic_raw</th>\n",
       "      <th>Topic_name</th>\n",
       "      <th>entities</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Mobile &amp; Apps FILE - In this July 9, 2015, fil...</td>\n",
       "      <td>PepsiCo beats 3Q profit forecasts</td>\n",
       "      <td>Original</td>\n",
       "      <td>No Media</td>\n",
       "      <td>Blogs</td>\n",
       "      <td>mercedsunstar.com</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6:0.987499999969</td>\n",
       "      <td>terms14.png</td>\n",
       "      <td>elise amendola_file ap_the associated press_mo...</td>\n",
       "      <td>0.023824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Mobile &amp; Apps FILE - In this July 9, 2015, fil...</td>\n",
       "      <td>PepsiCo beats 3Q profit forecasts</td>\n",
       "      <td>Original</td>\n",
       "      <td>No Media</td>\n",
       "      <td>Blogs</td>\n",
       "      <td>mercedsunstar.com</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6:0.98908045974</td>\n",
       "      <td>terms14.png</td>\n",
       "      <td>elise amendola_file ap_the associated press_mo...</td>\n",
       "      <td>0.021588</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  index                                    Sound Bite Text  \\\n",
       "0           0      0  Mobile & Apps FILE - In this July 9, 2015, fil...   \n",
       "1           1      1  Mobile & Apps FILE - In this July 9, 2015, fil...   \n",
       "\n",
       "                               Title Post Type Media Type Source Type  \\\n",
       "0  PepsiCo beats 3Q profit forecasts  Original   No Media       Blogs   \n",
       "1  PepsiCo beats 3Q profit forecasts  Original   No Media       Blogs   \n",
       "\n",
       "              Domain  Richness Interests Positive Objects Negative Objects  \\\n",
       "0  mercedsunstar.com       1.0       NaN              NaN              NaN   \n",
       "1  mercedsunstar.com       1.0       NaN              NaN              NaN   \n",
       "\n",
       "   Topic_top Topic_id         Topic_raw   Topic_name  \\\n",
       "0          6        6  6:0.987499999969  terms14.png   \n",
       "1          6        6   6:0.98908045974  terms14.png   \n",
       "\n",
       "                                            entities  Sentiment  \n",
       "0  elise amendola_file ap_the associated press_mo...   0.023824  \n",
       "1  elise amendola_file ap_the associated press_mo...   0.021588  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.assign(Sentiment = sentiment_score)\n",
    "print(df.shape)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dump file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dump(df, \"df_sel_entities_sentiment.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
